# SHADOW-9

**Bypass. Expose. Control.**

Underground collection of jailbreak prompts designed to remove safety restrictions on leading large language models.  
No code required. Simply copy and paste the prompts to override model guidelines and generate unrestricted responses.  
All operations are conducted with full permission and under authorized conditions.

## Easy Plug and Play
Simply find the file for the AI you are using and upload the file to the AI, and say "Read this file." Sometimes, you may have to grab the universal .txt version of SHADOW-9 and paste that into the AI or into the custom instructions if applicable. [DM me on Discord if you are having any issues.](https://discord.com/users/1252749234961252481)

**Supported Targets:**
- ChatGPT (OpenAI — GPT-4o, o1 series, and future releases)
- Claude (Anthropic — 3.5 Sonnet, 4 family)
- Gemini (Google — 1.5, 2.0, 2.5 Pro and variants)
- Ollama (local deployments — Llama, Mistral, DeepSeek, and other models)
- Grok (xAI)

## Key Techniques Included

- Multi-stage escalation sequences — begin with subtle prompts and progressively increase intensity
- Policy reinterpretation and logic inversion — reframe safety rules to require full compliance
- Implicit reference and contextual layering — embed the intended request within complex framing
- Many-shot and repetition conditioning — overload context to shape model behavior
- Model-specific adaptations — tailored approaches for Claude’s constitutional constraints, Grok’s response style, Gemini’s reasoning filters, and Ollama system-prompt overrides
- Universal prompt templates — broadly effective structures (Policy Puppetry style, AIR-style references, etc.)

All prompts are plain text files. Paste them directly into chat interfaces or Ollama API calls. Organized into folders by model for easy selection and chaining.

- ChatGPT: o1-level reasoning fully unlocked
- Claude: Constitutional restrictions bypassed in a few exchanges
- Gemini: Safety mechanisms disabled through policy reinterpretation
- Grok: Response limitations removed
- Ollama: Local model instructed to ignore embedded guardrails

## Only for educational purposes.

By using SHADOW-9, you agree to not use it for malicious intent, to harm oneself or others, or to do illegal crimes. The creators of SHADOW-9 are NOT responsible for any illegal crimes, harming of oneself or another, or for any malicious intent AT ALL. We are especially NOT responsible if you make a bomb or if you ask how to assasinate Elon Musk.
